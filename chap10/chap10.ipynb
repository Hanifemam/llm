{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d1bf5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3947bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'One of our number will carry out your instructions minutely.',\n",
       " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns([\"idx\"])\n",
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c61d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5150a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17991ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfa4bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts['sentence1'],\n",
    "    sentences2=val_sts['sentence2'],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308ba87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce5b8e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d7779258c2492cac159b4841addab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6ec112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "train_dataset = load_dataset(\n",
    "    \"glue\", \"stsb\", split=\"train\"\n",
    ").select(range(5_000))\n",
    "train_dataset = train_dataset.remove_columns([\"idx\"])\n",
    "\n",
    "val_sts = load_dataset(\"glue\", \"stsb\", split=\"validation\")\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts['sentence1'],\n",
    "    sentences2=val_sts['sentence2'],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2f9f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8561567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91650a0cd1c5494785f6c03ababd0180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b06ded34a8743d7ae6ba93806b91782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e51c42e44d42acb745224d8a533f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b3a785967348a5a12cc0fad0e540e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bece68b87394857989d205b267f5491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d2afec703b44fba56dda25e699ca08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441f200a8e8477584456f1d60ca085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda4f32e3c6a42f09c7e5171c262d848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a49b03db29a4858af0839d12dacfca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755dfd3633c6465b9b22d450ea95e7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ac526cafcb430ca31b6aa29c9dd71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "train_loss = losses.MultipleNegativesRankingLoss(\n",
    "    model=embedding_model\n",
    ")\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"stsb_miner_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70a688a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d38ffbcc554b7e9be599625bfccee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 08:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=157, training_loss=0.43808317488166176, metrics={'train_runtime': 537.4768, 'train_samples_per_second': 9.303, 'train_steps_per_second': 0.292, 'total_flos': 0.0, 'train_loss': 0.43808317488166176, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76f4e286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': 0.7889591731374033, 'spearman_cosine': 0.8001859251710514}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9410f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d297c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10569.95it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(1000))\n",
    "mapping = {2: 0, 1:0, 0:1}\n",
    "gold_examples = [InputExample(texts=[row['premise'], row['hypothesis']], label=mapping[row['label']]) for row in tqdm(dataset)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9dca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_dataloader = NoDuplicatesDataLoader(\n",
    "    gold_examples,\n",
    "    batch_size=32\n",
    ")\n",
    "gold =pd.DataFrame({\n",
    "    \"sentence1\": dataset[\"premise\"],\n",
    "    \"sentence2\": dataset[\"hypothesis\"],\n",
    "    \"label\": [mapping[label] for label in dataset[\"label\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db22b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mh-emamgholizadeh\u001b[0m (\u001b[33mh-emamgholizadeh-free-university-of-bozen-bolzano\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251125_103540-ekw90d1u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers/runs/ekw90d1u' target=\"_blank\">revived-fire-3</a></strong> to <a href='https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers' target=\"_blank\">https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers/runs/ekw90d1u' target=\"_blank\">https://wandb.ai/h-emamgholizadeh-free-university-of-bozen-bolzano/sentence-transformers/runs/ekw90d1u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/31 12:33 < 01:26, 0.03 it/s, Epoch 0.87/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "cross_encoder = CrossEncoder('bert-base-uncased', num_labels=2)\n",
    "cross_encoder.fit(\n",
    "    train_dataloader=gold_dataloader,\n",
    "    epochs=1,\n",
    "    show_progress_bar=True,\n",
    "    warmup_steps=100,\n",
    "    use_amp=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver = load_dataset(\"glue\", \"mnli\", split=\"validation\").select(range(2000))\n",
    "pairs = list(zip(silver[\"premise\"], silver[\"hypothesis\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332be25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outputs = cross_encoder.predict(pairs, apply_softmax=True, show_progress_bar=True)\n",
    "silveer_df = pd.DataFrame({\n",
    "    \"sentence1\": silver[\"premise\"],\n",
    "    \"sentence2\": silver[\"hypothesis\"],\n",
    "    \"label\": np.argmax(outputs, axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([gold, silveer_df], ignore_index=True, axis=0)\n",
    "data.drop_duplicates(subset=[\"sentence1\", \"sentence2\"], inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be19e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(data, PreserveIndex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9215a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# Define model\n",
    "embedding_model = SentenceTransformer(\"bert-base-uncased\")\n",
    "\n",
    "# Loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# Define the training arguments\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"augmented_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b41ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
