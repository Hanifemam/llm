{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6238fd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "# Load an AI-generated image of a puppy playing in the snow\n",
    "puppy_path = \"https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/chapter09/images/puppy.png\"\n",
    "image = Image.open(urlopen(puppy_path)).convert(\"RGB\")\n",
    "caption = \"a puppy playing in the snow\"\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ddcf2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import CLIPTokenizerFast, CLIPProcessor, CLIPModel\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "clip_tokenizer = CLIPTokenizerFast.from_pretrained(model_id)\n",
    "\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_id)\n",
    "\n",
    "model = CLIPModel.from_pretrained(model_id)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
